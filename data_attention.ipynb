{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPi1IcvTu3dFl8j3+/kkJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ainsley-snell/Data_Mining_CS290/blob/main/data_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ainsley-snell/Data_Mining_CS290.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JIk2G7vMAhf",
        "outputId": "0b05fa63-1b89-4ae0-f388-9b7983b8c942"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Data_Mining_CS290'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 40 (delta 11), reused 19 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (40/40), 101.77 KiB | 3.63 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V_kz2rqSFABu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "qYPEbdSkFNtR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Data_Mining_CS290/SILVERBLAZE.txt\", \"r\") as f:\n",
        "    raw_text= f.read()\n"
      ],
      "metadata": {
        "id": "uSta4yyUFnhA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text= tokenizer.encode(raw_text)"
      ],
      "metadata": {
        "id": "CT538_v9HSXa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "IC7IoCuXHTn-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "gHKqeMQcIGdh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=4, max_length=2, stride=2)\n",
        "\n",
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "    break\n",
        "\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmvijHWOUI-C",
        "outputId": "0af7ccb9-4ccd-48cb-e7fc-47b2cdce7b1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4373,  379],\n",
              "        [ 290,  356],\n",
              "        [5193,  267],\n",
              "        [2722,  573]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=6, max_length=8, stride=3)\n",
        "\n",
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "    break\n",
        "\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DZ45y3tVVHq",
        "outputId": "3dba7cc2-a3bf-4f08-b54d-0e19edfbd189"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  553,   531, 21636,  9847,    11, 44514,    11,   355],\n",
              "        [21636,  9847,  1701,   198,   198,     1,    40,   423],\n",
              "        [ 1243,   878,   514,    13,  1318,   373,   257,  3091],\n",
              "        [   11,   284,  3977,  9626, 48209, 10695,    13,  9074],\n",
              "        [  338,  2156,    11,   810,   484,   550, 43743,   287],\n",
              "        [  262,  7468,   286,  1521,  1757, 15195,  6122, 16555]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in batch:\n",
        "    list= row.tolist()[0]\n",
        "    print(list)\n",
        "    decoded= tokenizer.decode(list)\n",
        "    print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBuiJ8ohLLGb",
        "outputId": "46bfc794-c15c-4ccd-b6cc-bbd85a25de4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[553, 531, 21636, 9847, 11, 44514, 11, 355]\n",
            ",\" said Colonel Ross, bluntly, as\n",
            "[531, 21636, 9847, 11, 44514, 11, 355, 616]\n",
            " said Colonel Ross, bluntly, as my\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 8\n",
        "output_dim = 4\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "\n",
        "print(embedding_layer.weight)\n",
        "\n",
        "# The embedding layer maps token ids to vectors.\n",
        "# Embedding vectors are the numerical reprentations of words that are used to create contextual relationships between words and other words.\n",
        "# When words are turned into vectors, the closer they are in value means the more similar they are. The LLM takes their proximity in value to properly assosiate words to eachother."
      ],
      "metadata": {
        "id": "RtmFK5IANVXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vectors = embedding_layer.weight.data\n",
        "print(embedding_vectors)"
      ],
      "metadata": {
        "id": "qEtn4JgOS2JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = embedding_vectors @ embedding_vectors.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "fqaPY6QaJxdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "attention_weights = torch.softmax( attention_scores, dim = -1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "0koe9QVgJ5jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights[0].sum()"
      ],
      "metadata": {
        "id": "l-5Ko8jJJ-0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = attention_weights @ embedding_vectors\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "tQ-aVlYqKBD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}