{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMZcSwjMNTtkNvGzciqsUm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ainsley-snell/Data_Mining_CS290/blob/main/data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6_UnU7wtF7ta"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ainsley-snell/Data_Mining_CS290/main/SILVERBLAZE.txt\n",
        "\n",
        "with(open(\"SILVERBLAZE.txt\", \"r\", encoding=\"utf-8\")) as f:\n",
        "    raw_text = f.read()\n",
        "raw_text[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "mSwOCfpVF-hz",
        "outputId": "385e0714-a2a4-4225-b71c-ff1d3cf7a6b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-13 19:10:45--  https://raw.githubusercontent.com/ainsley-snell/Data_Mining_CS290/main/SILVERBLAZE.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52531 (51K) [text/plain]\n",
            "Saving to: ‘SILVERBLAZE.txt.2’\n",
            "\n",
            "\rSILVERBLAZE.txt.2     0%[                    ]       0  --.-KB/s               \rSILVERBLAZE.txt.2   100%[===================>]  51.30K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-12-13 19:10:45 (10.6 MB/s) - ‘SILVERBLAZE.txt.2’ saved [52531/52531]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SILVER BLAZE\\n\\n\"I AM afraid, Watson, that I shall h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "39gge00IGCJy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)"
      ],
      "metadata": {
        "id": "myUgfXGlGFlK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(enc_text[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ruh8St_GGIrM",
        "outputId": "345744af-7eec-47c4-bc6b-9ff4664469f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50, 4146, 5959, 9878, 32, 21211, 198, 198, 1, 40, 3001, 7787, 11, 14959, 11, 326, 314, 2236, 423, 284]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( tokenizer.decode( enc_text[:2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sRrtvGaGJUY",
        "outputId": "8abecb90-958e-4cec-d4bc-baba8f000fc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len( enc_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1mWiTKbGMvw",
        "outputId": "6e7ea8db-c26a-4af9-cb8e-70336de4954c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12491"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,10):\n",
        "    print(\"Input:\", tokenizer.decode(enc_text[:i]), \"Target:\", tokenizer.decode([enc_text[i]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Km8nICGOX1",
        "outputId": "7bfb2056-a160-4131-cdd4-7c0e8f0065c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: S Target: IL\n",
            "Input: SIL Target: VER\n",
            "Input: SILVER Target:  BL\n",
            "Input: SILVER BL Target: A\n",
            "Input: SILVER BLA Target: ZE\n",
            "Input: SILVER BLAZE Target: \n",
            "\n",
            "Input: SILVER BLAZE\n",
            " Target: \n",
            "\n",
            "Input: SILVER BLAZE\n",
            "\n",
            " Target: \"\n",
            "Input: SILVER BLAZE\n",
            "\n",
            "\" Target: I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "CYAeIOxNGPze"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "Z8DgNNgYGT7y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pei9j0JDGVfq",
        "outputId": "461bfba1-cc70-4a11-ad73-9aa2a1b4c0e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   50,  4146,  5959,  9878],\n",
            "        [   32, 21211,   198,   198],\n",
            "        [    1,    40,  3001,  7787],\n",
            "        [   11, 14959,    11,   326],\n",
            "        [  314,  2236,   423,   284],\n",
            "        [  467,   553,   531, 17628],\n",
            "        [   11,   355,   356,  3332],\n",
            "        [  866,  1978,   284,   674]])\n",
            "\n",
            "Targets:\n",
            " tensor([[ 4146,  5959,  9878,    32],\n",
            "        [21211,   198,   198,     1],\n",
            "        [   40,  3001,  7787,    11],\n",
            "        [14959,    11,   326,   314],\n",
            "        [ 2236,   423,   284,   467],\n",
            "        [  553,   531, 17628,    11],\n",
            "        [  355,   356,  3332,   866],\n",
            "        [ 1978,   284,   674, 12607]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to apply the tokenizer's decoder to these IDs, the rows of the tensor `inputs` have to be converted into lists:\n",
        "for row in inputs:\n",
        "    print( tokenizer.decode( row.tolist() ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaExPd14GXKU",
        "outputId": "a0c5372c-17ff-4884-e026-a3962b78de58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SILVER BL\n",
            "AZE\n",
            "\n",
            "\n",
            "\"I AM afraid\n",
            ", Watson, that\n",
            " I shall have to\n",
            " go,\" said Holmes\n",
            ", as we sat\n",
            " down together to our\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we don't send these IDs to the LLM for training; we associate a vector a.k.a. tensor with each ID and then train the LLM on the vectors\n",
        "# as a first example, let's create embedding vectors of length 3 for each token in a vocabulary of 6 tokens\n",
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "embedding = torch.nn.Embedding( vocab_size, output_dim )\n",
        "print(embedding.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L5a93wYGY9r",
        "outputId": "2b2db553-cc01-437e-a139-0d1c9725c430"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.7076, -0.4452, -0.5832],\n",
            "        [ 0.8526,  1.1339,  1.5151],\n",
            "        [ 1.4928, -0.8930, -1.5079],\n",
            "        [ 0.7168,  0.1400,  0.0474],\n",
            "        [ 0.0139, -0.9869,  1.1930],\n",
            "        [ 2.5283, -0.9062, -0.1422]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# if you just want the tensor part of this without the requires_grad=True bit\n",
        "# method 1:\n",
        "embedding.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P27wKP2IGeaI",
        "outputId": "2096f857-4d0e-427c-bda1-8ac4077deb3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7076, -0.4452, -0.5832],\n",
              "        [ 0.8526,  1.1339,  1.5151],\n",
              "        [ 1.4928, -0.8930, -1.5079],\n",
              "        [ 0.7168,  0.1400,  0.0474],\n",
              "        [ 0.0139, -0.9869,  1.1930],\n",
              "        [ 2.5283, -0.9062, -0.1422]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you just want the tensor part of this without the requires_grad=True bit\n",
        "# method 1:\n",
        "embedding.weight.detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0SwOl-VGgym",
        "outputId": "6e9d1f4c-88d6-4e9b-daf0-fa2cf590b5fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7076, -0.4452, -0.5832],\n",
              "        [ 0.8526,  1.1339,  1.5151],\n",
              "        [ 1.4928, -0.8930, -1.5079],\n",
              "        [ 0.7168,  0.1400,  0.0474],\n",
              "        [ 0.0139, -0.9869,  1.1930],\n",
              "        [ 2.5283, -0.9062, -0.1422]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call this A for some examples:\n",
        "A = embedding.weight.detach()"
      ],
      "metadata": {
        "id": "Uvqf69FqIL59"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first row:\n",
        "A[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJCCOw6lGicu",
        "outputId": "2ca601b8-cac1-433b-87e1-92ae9f12f144"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7076, -0.4452, -0.5832])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second row:\n",
        "A[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93VrbVw6GnvR",
        "outputId": "637f3b04-8691-4f5b-ef3f-3678950e44e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8526, 1.1339, 1.5151])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first column:\n",
        "A[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9rxNUHgGoXI",
        "outputId": "7600a5d9-14a7-4700-ac55-7b6a3d8adbe8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7076, 0.8526, 1.4928, 0.7168, 0.0139, 2.5283])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# element in row 2, column 3:\n",
        "A[1,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYfaAKehGqgB",
        "outputId": "f3dd6b21-5398-4431-9391-9a13d84978a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.5151)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to create a tensor directly:\n",
        "x = torch.tensor([1.2,2.1])\n",
        "y = torch.tensor([2.7,1.5])\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpv9XPduHhn9",
        "outputId": "4be3395f-9796-40dc-e41d-d5833218744e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2000, 2.1000])\n",
            "tensor([2.7000, 1.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot( x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suQzlPWlHiEM",
        "outputId": "bee6fedc-8dcc-4b8d-b285-fbcc3c0d41da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.3900)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check:\n",
        "1.2*2.7 + 2.1*1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6qg3ji2Hli4",
        "outputId": "cc04f453-e0e8-40e6-ed97-1287ead6001d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.390000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}